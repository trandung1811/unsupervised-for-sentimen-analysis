{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "List = ['good', 'nice','great','love','like','consider','awsome','recommend','well',\n",
    "        'amaze','generous','delightful','comfortable','absolutely','flesh','tasty','delicious','better','excellent','wonderful']\n",
    "center_class = {}\n",
    "def clusters(word_vectors):\n",
    "    \n",
    "    model = KMeans(n_clusters=2, max_iter= 10000, random_state=True, n_init=100).fit(X=word_vectors.vectors)\n",
    "    \n",
    "    K_0 = model.cluster_centers_[0]\n",
    "    K_1 = model.cluster_centers_[1]\n",
    "    dic = {}\n",
    "    for item in List:\n",
    "        if item in word_vectors.vocab.keys():\n",
    "             dic[item] = word_vectors[item]\n",
    "        \n",
    "    frame = pd.DataFrame(dic.keys())\n",
    "    frame.columns = ['words']\n",
    "    frame['vectors'] = frame.words.apply(lambda x: dic[x])\n",
    "    frame['distance'] = frame.vectors.apply(lambda x: model.transform([x]))\n",
    "    frame['K_0_distance'] = frame.distance.apply(lambda x: x[0][0])\n",
    "    frame['K_1_distance'] = frame.distance.apply(lambda x: x[0][1])\n",
    "    num0 = frame.K_0_distance.sum()\n",
    "    num1 = frame.K_1_distance.sum()\n",
    "    if num0 < num1: \n",
    "        center_class[0] = 1\n",
    "        center_class[1] = -1\n",
    "    else:\n",
    "        center_class[0] = -1\n",
    "        center_class[1] = 1\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(word_vectors, model):\n",
    "    \n",
    "    words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "    words.columns = ['words']\n",
    "    words['vectors'] = words.words.apply(lambda x: word_vectors[x])\n",
    "    words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "    words.cluster = words.cluster.apply(lambda x: x[0])\n",
    "    words['cluster_value'] = [center_class[i] for i in words.cluster]\n",
    "    words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "    words['sentiment_coeff'] = words.closeness_score * words.cluster_value\n",
    "    sentiment_dict  = words.set_index('words')['sentiment_coeff'].to_dict()\n",
    " \n",
    "    return sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    word_vectors = Word2Vec.load('./imdb.d2v').wv\n",
    "    model = clusters(word_vectors)\n",
    "    sentiment_dict = sentiment_score(word_vectors,model)\n",
    "    f = open('sentiment_dict.txt','w')\n",
    "    for key in sentiment_dict:\n",
    "        f.write(str(key) + \" \" + str(sentiment_dict[key]) + '\\n')\n",
    "    f.close()\n",
    "    print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
